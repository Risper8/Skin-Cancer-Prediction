{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import datasets, models\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opendatasets --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  risperndirangu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Kaggle Key:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/pritpal2873/multiple-skin-disease-detection-and-classification\n",
      "Downloading multiple-skin-disease-detection-and-classification.zip to .\\multiple-skin-disease-detection-and-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▌                                                                           | 35.0M/785M [01:12<22:50, 573kB/s]"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "dataset=('https://www.kaggle.com/datasets/pritpal2873/multiple-skin-disease-detection-and-classification')\n",
    "\n",
    "od.download(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/kaggle/input/multiple-skin-disease-detection-and-classification/Skin Cancer Dataset/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m basedir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/multiple-skin-disease-detection-and-classification/Skin Cancer Dataset/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m directory \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbasedir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m directory\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/kaggle/input/multiple-skin-disease-detection-and-classification/Skin Cancer Dataset/'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "basedir = '/kaggle/input/multiple-skin-disease-detection-and-classification/Skin Cancer Dataset/'\n",
    "directory = os.listdir(basedir)\n",
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = {}\n",
    "for idx, name in enumerate(directory):\n",
    "  encoder[name]=idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "labels=[]\n",
    "for folder in directory:\n",
    "  pth = basedir+folder\n",
    "  imagepth = os.listdir(pth)\n",
    "  for image in tqdm(imagepth):\n",
    "    pthimage = pth+'/'+image\n",
    "    if 'csv' not in pthimage:\n",
    "        images.append(pthimage)\n",
    "        labels.append(folder)\n",
    "    else:\n",
    "        print(pthimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame()\n",
    "data['label'] = labels\n",
    "data['path'] = images\n",
    "data['encode_labels'] = data['label'].map(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = cv2.imread(images[0])\n",
    "plt.imshow(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Image.open(images[0])\n",
    "s = s.resize((256,256))\n",
    "s.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data['path'].tolist(),data['encode_labels'].tolist()\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "      transforms.ToTensor(),\n",
    "      transforms.RandomRotation(10),\n",
    "      transforms. RandomHorizontalFlip(), \n",
    "      transforms.Resize(size=(256,256)),  \n",
    "      transforms.CenterCrop(size=(256,256)),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "     ]\n",
    "    )\n",
    "valid_transform = transforms.Compose(\n",
    "    [\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Resize(size=(256,256)),\n",
    "     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define dataset\n",
    "class Mdataset(Dataset):\n",
    "  def __init__(self,x,y,transform=None):\n",
    "    self.x = x\n",
    "    self.y = y\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.y)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    x = Image.open(self.x[idx])\n",
    "    x = np.asarray(x)\n",
    "    # x = x.resize((256,256))\n",
    "    # x = cv2.imread(self.x[idx])\n",
    "    y = torch.tensor(self.y[idx],dtype=torch.long)\n",
    "    if self.transform != None:\n",
    "      x = self.transform(x)\n",
    "\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train loader\n",
    "traindataset = Mdataset(x=X_train,y=y_train,transform=train_transform)\n",
    "trainloader = DataLoader(traindataset,batch_size=32)\n",
    "#test loader\n",
    "testdataset = Mdataset(x=X_test,y=y_test,transform=valid_transform)\n",
    "testloader = DataLoader(testdataset,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in trainloader:\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Size([32, 12, 126, 126])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = len(data['label'].unique())\n",
    "class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(weights='IMAGENET1K_V1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 9)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "# TRAINING\n",
    "t = time.process_time()\n",
    "error_counts = 0\n",
    "epoch_num = 50\n",
    "epoch_loss_values = []\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "\n",
    "    print('-' * 10)\n",
    "    print(f\"epoch {epoch + 1}/{epoch_num}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    try:\n",
    "        for batch_data in trainloader:\n",
    "    #         try:\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            step += 1\n",
    "            inputs = batch_data[0].to(device)\n",
    "            labels = batch_data[1].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            # labels = labels.unsqueeze(1)  # Adds an additional dimension\n",
    "\n",
    "            # labels = labels.view(32)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            print(f\"{step}/{len(traindataset) // trainloader.batch_size}, train_loss: {loss.item():.4f}\")\n",
    "            epoch_len = len(traindataset) // trainloader.batch_size\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor([], dtype=torch.long, device=device)\n",
    "        for val_data in tqdm(testloader):\n",
    "            val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "            y_pred = torch.cat([y_pred, model(val_images)], dim=0)\n",
    "            y = torch.cat([y, val_labels], dim=0)\n",
    "    y_pred = torch.argmax(y_pred,dim=1)\n",
    "    score = accuracy_score(y.cpu(),y_pred.cpu())\n",
    "    print('============ACCURACY=======',score)\n",
    "    if score > 0.8:\n",
    "      break\n",
    "#     else:\n",
    "#         scheduler.step()\n",
    "        \n",
    "    time.sleep(1)\n",
    "print(f\"train completed, best_metric: {score:.4f} at epoch: {epoch}\")\n",
    "elapsed_time = time.process_time() - t\n",
    "elapsed_time"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5138420,
     "sourceId": 8807363,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
