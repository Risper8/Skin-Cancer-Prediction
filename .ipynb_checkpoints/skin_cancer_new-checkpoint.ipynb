{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uofvgX6CL6xf"
      },
      "outputs": [],
      "source": [
        "## importing libraries\n",
        "#libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import matplotlib.pyplot as plt\n",
        "import pydot\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import applications,activations\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers,utils\n",
        "from keras.models import Sequential, Model\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D, Flatten,Dense, MaxPool2D, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3Out6nF4sx_",
        "outputId": "b803e070-ba4b-434d-f7de-f452fede1566"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "irUhoe3mMXAj"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1I_P0quMo_a",
        "outputId": "0f8bed47-5813-4204-d1c1-46988b709e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping, found downloaded files in \"./multiple-skin-disease-detection-and-classification\" (use force=True to force download)\n"
          ]
        }
      ],
      "source": [
        " import opendatasets as od\n",
        " dataset=('https://www.kaggle.com/datasets/pritpal2873/multiple-skin-disease-detection-and-classification')\n",
        "\n",
        " od.download(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUiRTpy2M5Ex",
        "outputId": "5760ef1e-dcf6-4272-ac9d-4b0a2519e241"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Acitinic Keratosis',\n",
              " 'Basal Cell Carcinoma',\n",
              " 'Nevus',\n",
              " 'Melanoma',\n",
              " 'Pigmented Benign Keratosis',\n",
              " 'Dermatofibroma',\n",
              " 'Vascular Lesion',\n",
              " 'Squamous Cell Carcinoma',\n",
              " 'Seborrheic Keratosis']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import os\n",
        "basedir = '/content/drive/MyDrive/SYMPTOMS SKIN/multiple-skin-disease-detection-and-classification/Skin Cancer Dataset/'\n",
        "directory = os.listdir(basedir)\n",
        "directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "gT-9Y5UwP6hO"
      },
      "outputs": [],
      "source": [
        "encoder = {}\n",
        "for idx, name in enumerate(directory):\n",
        "  encoder[name]=idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C2WDrTEVnnK"
      },
      "source": [
        "## loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kufCxXOgQP32",
        "outputId": "18a9fc02-016a-4d25-eba4-3f4889166b36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:00<00:00, 616265.65it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 560436.13it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 251879.89it/s]\n",
            "100%|██████████| 505/505 [00:00<00:00, 524028.58it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 370063.88it/s]\n",
            "100%|██████████| 400/400 [00:00<00:00, 282873.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SYMPTOMS SKIN/multiple-skin-disease-detection-and-classification/Skin Cancer Dataset/Dermatofibroma/metadata.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 290/290 [00:00<00:00, 266450.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SYMPTOMS SKIN/multiple-skin-disease-detection-and-classification/Skin Cancer Dataset/Vascular Lesion/metadata.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 414/414 [00:00<00:00, 306142.78it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 525338.68it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "images=[]\n",
        "labels=[]\n",
        "for folder in directory:\n",
        "  pth = basedir+folder\n",
        "  imagepth = os.listdir(pth)\n",
        "  for image in tqdm(imagepth):\n",
        "    pthimage = pth+'/'+image\n",
        "    if 'csv' not in pthimage:\n",
        "        images.append(pthimage)\n",
        "        labels.append(folder)\n",
        "    else:\n",
        "        print(pthimage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XflcszRMWM68"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.DataFrame()\n",
        "data['label'] = labels\n",
        "data['path'] = images\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding image pixels\n",
        "data['image_pixel'] = data['path'].map(lambda x: np.asarray(Image.open(x).resize((112,112))))\n",
        "data['encode_labels'] = data['label'].map(encoder)"
      ],
      "metadata": {
        "id": "WsqqwkRG6JCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wXSAfRVaXRy"
      },
      "outputs": [],
      "source": [
        "data.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmNQfOsBajYz"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kp6XbLcRabHp"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1DjLTcbapuK"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYuN46LTa202"
      },
      "source": [
        "## splitting dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataframe into training, validation, and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(data, test_size=0.2, random_state=42)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "rJDMMxMhOUgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.columns)\n",
        "print(val_df.columns)\n",
        "print(test_df.columns)\n"
      ],
      "metadata": {
        "id": "c0SBUS8qd3KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create a custom data generator\n",
        "class MultiOutputDataGenerator(ImageDataGenerator):\n",
        "    def flow_from_dataframe(self, dataframe, directory=None, x_col='file_path', y_col=None, target_size=(256, 256), color_mode='rgb',\n",
        "                            classes=None, class_mode='categorical', batch_size=32, shuffle=True, seed=None):\n",
        "        gen = super().flow_from_dataframe(\n",
        "            dataframe=dataframe,\n",
        "            directory=directory,\n",
        "            x_col=x_col,\n",
        "            y_col=y_col,\n",
        "            target_size=target_size,\n",
        "            color_mode=color_mode,\n",
        "            classes=classes,\n",
        "            class_mode=class_mode,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            seed=seed\n",
        "        )\n",
        "        while True:\n",
        "            x_batch, y_batch = gen.next()\n",
        "            yield x_batch, y_batch\n",
        "\n",
        "# Create an instance of the data generator\n",
        "datagen = MultiOutputDataGenerator(rescale=1./255,\n",
        "                                  # rotation_range = 10,\n",
        "                                  # zoom_range=20,\n",
        "                                  width_shift_range = 0.2,\n",
        "                                  height_shift_range = 0.2,\n",
        "                                  shear_range = 0.2,\n",
        "                                  horizontal_flip = True,\n",
        "                                  # vertical_flip = True,\n",
        "                                  fill_mode = 'nearest')\n",
        "\n",
        "# Create the generator\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='path',\n",
        "    y_col='label',  # Specify the label column\n",
        "    target_size=(112, 112),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "val_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col='path',\n",
        "    y_col='label',  # Specify the label column\n",
        "    target_size=(112, 112),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='path',\n",
        "    y_col='label',  # Specify the label column\n",
        "    target_size=(112, 112),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "id": "2zu0sMHXOdI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['label'].unique()"
      ],
      "metadata": {
        "id": "ZjwyFn2ca1hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in train_generator:\n",
        "  break"
      ],
      "metadata": {
        "id": "WduclPeegXEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n60aRsBefqPW"
      },
      "source": [
        "## modelling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_model():\n",
        "#   model = Sequential()\n",
        "#   model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', input_shape=(56,56,3))),\n",
        "#   model.add(BatchNormalization()),\n",
        "#   model.add(MaxPool2D(pool_size=(2,2), strides=2)),\n",
        "#   model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu')),\n",
        "#   model.add(MaxPool2D(pool_size=(2,2), strides=2)),\n",
        "#   model.add(Flatten()),\n",
        "#   model.add(Dense(units=9, activation='softmax'))\n",
        "#   print(model.summary())\n",
        "# #     tf.keras.utils.plot_model(model, to_file=\"model.png\")\n",
        "#   return model;\n"
      ],
      "metadata": {
        "id": "riAf1PzfStc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qS563A7rgPm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "# from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "def create_model(num_classes, freeze_base_model=True):\n",
        "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(112, 112, 3))\n",
        "    base_model.trainable = not freeze_base_model\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=outputs)\n",
        "    # optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, beta_1=0.9, beta_2=0.999, amsgrad=False, epsilon=1e-08)\n",
        "\n",
        "    # model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQLw6mKigedp"
      },
      "outputs": [],
      "source": [
        "# Y_train_flat = Y_train.ravel()\n",
        "# Y_train_flat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6ds_E4_gjNl"
      },
      "outputs": [],
      "source": [
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "# import numpy as np\n",
        "# classes = np.unique(Y_train_flat)\n",
        "\n",
        "# class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=Y_train_flat)\n",
        "# class_weights= dict(zip(classes, class_weights))\n",
        "\n",
        "# class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvxEBPYxgyLx"
      },
      "outputs": [],
      "source": [
        "# def train_model():\n",
        "#     early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1,\n",
        "#                            mode='auto', restore_best_weights=True)\n",
        "\n",
        "#     reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5,\n",
        "\n",
        "#                               verbose=1, mode='auto')\n",
        "#     train_steps_per_epoch = 2628// 80\n",
        "#     validation_steps = 657//80\n",
        "#     history = model.fit(\n",
        "#                       train_generator,\n",
        "#                       # epochs=50,\n",
        "#                       validation_data=val_generator,\n",
        "#                       steps_per_epoch=train_generator,\n",
        "#                       validation_steps=val_generator,\n",
        "#                       callbacks = [reduce_lr, early_stop]\n",
        "#                       )\n",
        "\n",
        "#     # history = model.fit(X_train,\n",
        "#     #                     Y_train,\n",
        "#     #                     validation_split=0.2,\n",
        "#     #                     batch_size = 20,\n",
        "#     #                     epochs = EPOCHS,\n",
        "#     #                     class_weight=class_weights,\n",
        "#     #                     callbacks = [reduce_lr, early_stop])\n",
        "#     return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0LeEg-Cg2bi"
      },
      "outputs": [],
      "source": [
        "def test_model(model, X_test, Y_test):\n",
        "    model_acc = model.evaluate(X_test, Y_test, verbose=0)[1]\n",
        "    print(\"Test Accuracy: {:.3f}%\".format(model_acc * 100))\n",
        "    y_true = np.array(Y_test)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred = np.array(list(map(lambda x: np.argmax(x), y_pred)))\n",
        "    clr = classification_report(y_true, y_pred, target_names= data['label'].unique())\n",
        "    print(clr)\n",
        "    # conf_matrix = confusion_matrix(y_true, npred)\n",
        "    # print(clr)\n",
        "    # target_names= data['label'].unique()\n",
        "    # # Plot confusion matrix\n",
        "    # plt.figure(figsize=(10, 8))\n",
        "    # sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "    # plt.xlabel('Predicted')\n",
        "    # plt.ylabel('True')\n",
        "    # plt.title('Confusion Matrix')\n",
        "    # plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8DKFZgrs-WR"
      },
      "outputs": [],
      "source": [
        "num_classes = 9\n",
        "model = create_model(num_classes)\n",
        "# model=create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "jh4T-BYlg8vn",
        "outputId": "23b776a9-be50-4c33-ca98-52271bce18ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "82/82 [==============================] - 203s 1s/step - loss: 2.1948 - accuracy: 0.1198 - val_loss: 2.1901 - val_accuracy: 0.1200 - lr: 0.0020\n",
            "Epoch 2/50\n",
            "82/82 [==============================] - 121s 1s/step - loss: 2.1917 - accuracy: 0.1210 - val_loss: 2.1933 - val_accuracy: 0.1072 - lr: 0.0020\n",
            "Epoch 3/50\n",
            "26/82 [========>.....................] - ETA: 46s - loss: 2.1843 - accuracy: 0.1118"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-39413aa40c26>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1,\n",
        "                         mode='auto', restore_best_weights=True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5,\n",
        "\n",
        "                              verbose=1, mode='auto')\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-3, beta_1=0.9, beta_2=0.999, amsgrad=False, epsilon=1e-08)\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "                 optimizer = optimizer,\n",
        "                  metrics = ['accuracy'])\n",
        "\n",
        "train_samples = 2628\n",
        "val_samples = 657\n",
        "batch_size = 32\n",
        "\n",
        "# Calculate steps per epoch\n",
        "train_steps_per_epoch = train_samples // batch_size\n",
        "validation_steps = val_samples // batch_size\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=val_generator,\n",
        "    steps_per_epoch=train_steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[reduce_lr, early_stop]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJTs75fghA73"
      },
      "outputs": [],
      "source": [
        "test_model(model, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0VkLrZajeqt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}